import pandas as pd
import numpy as np
import pinecone
import os
import time
from sqlalchemy import create_engine
from langchain_community.embeddings import OpenAIEmbeddings

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
openai_api_key = os.environ.get("OPENAI_API_KEY")
pinecone_api_key = os.environ.get("PINECONE_API_KEY")
pinecone_index_name = os.environ.get("PINECONE_INDEX_NAME")

# Pinecone ìµœì‹  SDK ë°©ì‹ìœ¼ë¡œ ì´ˆê¸°í™”
pc = pinecone.Pinecone(api_key=pinecone_api_key)

# Pinecone ì¸ë±ìŠ¤ í™•ì¸ ë° ìƒì„±
dimension = 1536
try:
    indexes = pc.list_indexes().names()
    if pinecone_index_name not in indexes:
        print(f"ğŸ”¹ {pinecone_index_name} ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        pc.create_index(name=pinecone_index_name, dimension=dimension, metric="cosine")

        # ì¸ë±ìŠ¤ ìƒì„±ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        print("â³ ì¸ë±ìŠ¤ ìƒì„± ì¤‘... ì ì‹œ ëŒ€ê¸°í•©ë‹ˆë‹¤.")
        time.sleep(10)  # ì´ˆê¸° ëŒ€ê¸°
        while pinecone_index_name not in pc.list_indexes().names():
            print("â³ ì¸ë±ìŠ¤ ìƒì„± ì¤‘... ê³„ì† ëŒ€ê¸°í•©ë‹ˆë‹¤.")
            time.sleep(5)
except Exception as e:
    print(f"âŒ Pinecone ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    raise

try:
    # ìµœì‹  Pinecone SDK ë°©ì‹ìœ¼ë¡œ ì¸ë±ìŠ¤ ì ‘ê·¼
    index = pc.Index(pinecone_index_name)
    embedding_model = OpenAIEmbeddings(api_key=openai_api_key, model="text-embedding-3-small")
except Exception as e:
    print(f"âŒ Pinecone ì¸ë±ìŠ¤ ì—°ê²° ë˜ëŠ” ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    raise

# MySQL ì—°ê²°
engine = create_engine('mysql+pymysql://teamuser:StM!chel1905@3.34.46.30/dev_db')


def fetch_data_with_retry(query, engine, retries=3, delay=5):
    """SQL ì‹¤í–‰ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¬ì‹œë„"""
    for attempt in range(retries):
        try:
            df = pd.read_sql(query, engine)
            return df
        except Exception as e:
            print(f"âš ï¸ SQL ì‹¤í–‰ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{retries}): {e}")
            time.sleep(delay)
    print("âŒ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨: SQL ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return pd.DataFrame()


def upload_to_pinecone(df, namespace, batch_size=100):
    """ë°ì´í„°í”„ë ˆì„ì„ Pineconeì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    if df.empty:
        print(f"âš ï¸ {namespace} ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    total_rows = len(df)
    print(f"ğŸš€ {namespace} ë°ì´í„° ({total_rows}í–‰) ë²¡í„°í™” ë° Pinecone ì—…ë¡œë“œ ì‹œì‘...")

    # ë©”íƒ€ë°ì´í„° í¬ê¸° ì œí•œì„ ìœ„í•œ ìµœëŒ€ í…ìŠ¤íŠ¸ ê¸¸ì´ ì„¤ì •
    MAX_METADATA_LENGTH = 30000  # Pinecone ë©”íƒ€ë°ì´í„° í¬ê¸° ì œí•œì— ë§ê²Œ ì¡°ì •

    uploaded_count = 0
    error_count = 0

    try:
        # ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  í–‰ë³„ë¡œ ê²°í•©
        text_data = df.astype(str).apply(lambda row: ", ".join(row), axis=1).tolist()

        # ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
        for i in range(0, len(text_data), batch_size):
            batch_texts = text_data[i:i + batch_size]

            try:
                # ì„ë² ë”© ìƒì„±
                vectors = embedding_model.embed_documents(batch_texts)
                vectors = np.array(vectors).astype('float32')

                # IDì™€ ë©”íƒ€ë°ì´í„° ìƒì„±
                batch_ids = [f"{namespace}_{idx}" for idx in range(i, i + len(batch_texts))]
                batch_metadata = []

                # ë©”íƒ€ë°ì´í„° í¬ê¸° ì œí•œ ì ìš©
                for text in batch_texts:
                    # ë©”íƒ€ë°ì´í„° í¬ê¸° ì œí•œì„ ìœ„í•´ í…ìŠ¤íŠ¸ ì˜ë¼ë‚´ê¸°
                    if len(text) > MAX_METADATA_LENGTH:
                        text = text[:MAX_METADATA_LENGTH] + "... (ì˜ë¦¼)"
                    batch_metadata.append({"original_text": text})

                # Pineconeì— ì—…ë¡œë“œ
                index.upsert(
                    vectors=list(zip(batch_ids, vectors, batch_metadata)),
                    namespace=namespace
                )

                uploaded_count += len(batch_texts)
                print(f"ğŸ“Š ì§„í–‰ ìƒí™©: {uploaded_count}/{total_rows} í–‰ ì—…ë¡œë“œ ì™„ë£Œ")

            except Exception as e:
                error_count += len(batch_texts)
                print(f"âš ï¸ ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨ (í–‰ {i}~{i + len(batch_texts) - 1}): {e}")
                # 10ì´ˆ ëŒ€ê¸° í›„ ê³„ì† ì§„í–‰
                time.sleep(10)
                continue

    except Exception as e:
        print(f"âŒ ë²¡í„°í™” ë˜ëŠ” ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    print(f"âœ… {namespace} ë°ì´í„° {uploaded_count}ê°œ ì—…ë¡œë“œ ì™„ë£Œ! (ì˜¤ë¥˜: {error_count}ê°œ)")


if __name__ == "__main__":
    queries = {
        "sales": """
                SELECT 
                    o.store, i.item_id, i.item_name, DATE(o.order_at) AS order_date, 
                    SUM(oi.item_count) AS total_sold, 
                    SUM(oi.item_count * i.sale_price) AS total_amount
                FROM kiosk_orderitem oi
                JOIN kiosk_orderinfo o ON oi.order_id = o.order_id
                JOIN menu_item i ON oi.item_id = i.item_id
                GROUP BY o.store, i.item_id, i.item_name, order_date
                ORDER BY o.store, order_date DESC, total_sold DESC;
            """,
        "members": """
                WITH FavoriteProducts AS (
                    SELECT 
                        m.member_id, m.name AS member_name, i.item_name, COUNT(*) AS product_count,
                        RANK() OVER (PARTITION BY m.member_id ORDER BY COUNT(*) DESC) AS product_rank
                    FROM kiosk_orderinfo o
                    JOIN kiosk_paymentinfo p ON o.order_id = p.order_id
                    JOIN member_member m ON p.member_id = m.member_id
                    JOIN kiosk_orderitem oi ON o.order_id = oi.order_id
                    JOIN menu_item i ON oi.item_id = i.item_id
                    GROUP BY m.member_id, i.item_name
                )
                SELECT 
                    m.member_id, m.name AS member_name, COUNT(DISTINCT o.order_id) AS total_orders,
                    SUM(o.final_amount) AS total_spent,
                    GROUP_CONCAT(DISTINCT fp.item_name ORDER BY fp.product_rank SEPARATOR ', ') AS favorite_products
                FROM member_member m
                LEFT JOIN kiosk_paymentinfo p ON m.member_id = p.member_id
                LEFT JOIN kiosk_orderinfo o ON p.order_id = o.order_id
                LEFT JOIN FavoriteProducts fp ON m.member_id = fp.member_id AND fp.product_rank <= 3
                GROUP BY m.member_id, m.name
                ORDER BY total_spent DESC;
            """,
        "orders": """
                SELECT 
                    o.order_id, o.store, o.order_at, m.member_id, m.name AS member_name, 
                    o.final_amount, p.payment_method AS payment_type, 
                    i.item_id, i.item_name, oi.item_count
                FROM kiosk_orderinfo o
                LEFT JOIN kiosk_paymentinfo p ON o.order_id = p.order_id
                LEFT JOIN member_member m ON p.member_id = m.member_id
                LEFT JOIN kiosk_orderitem oi ON o.order_id = oi.order_id
                LEFT JOIN menu_item i ON oi.item_id = i.item_id
                ORDER BY o.order_at DESC;
            """,
        "qna": """
                SELECT 
                    q.qna_id, q.title AS question_title, q.content AS question_content, 
                    r.content AS answer, q.created_at AS question_date, r.created_at AS answer_date
                FROM member_qna q
                LEFT JOIN member_qnareply r ON q.qna_id = r.qna_id
                ORDER BY q.created_at DESC
                LIMIT 10;
            """
    }

    try:
        for namespace, query in queries.items():
            print(f"\nğŸ” {namespace} ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹œì‘...")
            df = fetch_data_with_retry(query, engine)
            if not df.empty:
                upload_to_pinecone(df, namespace)
            else:
                print(f"âš ï¸ {namespace} ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        # ì¢…ë£Œ ì‹œ ì—°ê²° í•´ì œ
        engine.dispose()
        print("\nğŸš€ ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ!")