import pandas as pd
import numpy as np
import pinecone
import os
import time
from sqlalchemy import create_engine
from langchain_community.embeddings import OpenAIEmbeddings

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
openai_api_key = os.environ.get("OPENAI_API_KEY")
pinecone_api_key = os.environ.get("PINECONE_API_KEY")
pinecone_index_name = os.environ.get("PINECONE_INDEX_NAME")

# Pinecone ì´ˆê¸°í™”
pinecone.init(api_key=pinecone_api_key, environment="gcp-starter")

# Pinecone ì¸ë±ìŠ¤ í™•ì¸ ë° ìƒì„±
dimension = 1536
if pinecone_index_name not in pinecone.list_indexes():
    print(f"ğŸ”¹ {pinecone_index_name} ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
    pinecone.create_index(name=pinecone_index_name, dimension=dimension, metric="cosine")

# ì¸ë±ìŠ¤ ìƒì„±ë  ë•Œê¹Œì§€ ëŒ€ê¸°
while pinecone_index_name not in pinecone.list_indexes():
    print("â³ ì¸ë±ìŠ¤ ìƒì„± ì¤‘... ì ì‹œ ëŒ€ê¸°í•©ë‹ˆë‹¤.")
    time.sleep(5)

index = pinecone.Index(pinecone_index_name)  # ì•ˆì „í•œ ì´ˆê¸°í™”
embedding_model = OpenAIEmbeddings(api_key=openai_api_key, model="text-embedding-3-small")

# MySQL ì—°ê²°
engine = create_engine('mysql+pymysql://teamuser:StM!chel1905@3.34.46.30/dev_db')


def fetch_data_with_retry(query, engine, retries=3, delay=5):
    """SQL ì‹¤í–‰ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¬ì‹œë„"""
    for attempt in range(retries):
        try:
            df = pd.read_sql(query, engine)
            return df
        except Exception as e:
            print(f"âš ï¸ SQL ì‹¤í–‰ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{retries}): {e}")
            time.sleep(delay)
    print("âŒ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨: SQL ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return pd.DataFrame()


def upload_to_pinecone(df, namespace, batch_size=100):
    """ë°ì´í„°í”„ë ˆì„ì„ Pineconeì— ì—…ë¡œ"""
    if df.empty:
        print(f"âš ï¸ {namespace} ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    print(f"ğŸš€ {namespace} ë°ì´í„° ë²¡í„°í™” ë° Pinecone ì—…ë¡œë“œ ì‹œì‘...")

    text_data = df.astype(str).apply(lambda row: ", ".join(row), axis=1).tolist()
    vectors = embedding_model.embed_documents(text_data)
    vectors = np.array(vectors).astype('float32')

    for i in range(0, len(vectors), batch_size):
        batch_vectors = vectors[i: i + batch_size]
        batch_ids = [f"{namespace}_{idx}" for idx in range(i, i + len(batch_vectors))]
        batch_metadata = [{"original_text": text_data[idx]} for idx in range(i, i + len(batch_vectors))]

        index.upsert(
            vectors=list(zip(batch_ids, batch_vectors, batch_metadata)),
            namespace=namespace
        )

    print(f"âœ… {namespace} ë°ì´í„° {len(df)}ê°œ ì—…ë¡œë“œ ì™„ë£Œ!")


if __name__ == "__main__":
    queries = { ... }  # ê¸°ì¡´ SQL ì¿¼ë¦¬ ìœ ì§€

    for namespace, query in queries.items():
        df = fetch_data_with_retry(query, engine)
        if not df.empty:
            upload_to_pinecone(df, namespace)

    engine.dispose()
    print("ğŸš€ ëª¨ë“  ë°ì´í„°ê°€ Pineconeì— ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
