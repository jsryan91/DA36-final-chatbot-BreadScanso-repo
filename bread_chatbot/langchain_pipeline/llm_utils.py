import os
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
anthropic_api_key = os.getenv("ANTHROPIC_API_KEY")


# API í˜¸ì¶œ í•¨ìˆ˜ (LangChain ë°©ì‹ìœ¼ë¡œ ê°„ì†Œí™”)
def call_api(prompt, model="gpt-4o"):
    """LangChainì„ ì´ìš©í•´ LLM APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    try:
        chain = create_chain("You are an AI assistant specializing in SQL and data analysis.", model)
        return chain.invoke({"input": prompt})
    except Exception as e:
        print(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."


# ê²°ê³¼ë¥¼ ìì—°ì–´ë¡œ ë³€í™˜ (í•¨ìˆ˜ ìì²´ëŠ” ìœ ì§€, ë‚´ë¶€ì ìœ¼ë¡œ LangChain í™œìš©)
def response_nlp(user_question, query, query_result, history_text=""):
    prompt = f"""ë‹¹ì‹ ì€ ë² ì´ì»¤ë¦¬ì˜ ì¹œì ˆí•œ ë§¤ì¶œ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
    ì´ì „ ëŒ€í™” ê¸°ë¡:
    {history_text}
    ì‚¬ìš©ìì˜ ì§ˆë¬¸:
    {user_question}

    ì‹¤í–‰ëœ SQL ì¿¼ë¦¬:
    {query}

    ë‹¤ìŒ SQL ì‹¤í–‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•  ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”:
    {query_result}
    """
    return call_api(prompt)

# ğŸ¦œë­ì²´ì¸
def get_llm(model="gpt-4o"):
    """ëª¨ë¸ ì´ë¦„ì— ë”°ë¼ ì ì ˆí•œ LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if model.startswith("gpt"):
        return ChatOpenAI(
            model=model,
            openai_api_key=openai_api_key,
            temperature=0.1
        )
    elif model.startswith("claude"):
        return ChatAnthropic(
            model=model,
            anthropic_api_key=anthropic_api_key,
            temperature=0.1
        )
    else:
        # ê¸°ë³¸ê°’ì€ gpt-4o
        return ChatOpenAI(
            model="gpt-4o",
            openai_api_key=openai_api_key,
            temperature=0.1
        )


# ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ ì²´ì¸ ìƒì„±
def create_chain(system_prompt, model="gpt-4o"):
    """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ì„ ì…ë ¥ë°›ì•„ LangChain ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    llm = get_llm(model)

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}")
    ])

    chain = prompt | llm | StrOutputParser()
    return chain