from fastapi import APIRouter
from bread_chatbot.langchain_pipeline.pipeline import LangChainPipeline
from pydantic import BaseModel


# ==================    <<  ë¶ˆëŸ¬ì˜¤ê¸°/ê²½ë¡œì§€ì •  >> =========================

# 1. ë¼ìš°í„° ì„¤ì •
router = APIRouter()

# 2. íŒŒì´í”„ë¼ì¸
pipeline = LangChainPipeline()

# 3. ìš”ì²­ ëª¨ë¸ ì •ì˜
class QuestionRequest(BaseModel):
    question: str

# ==================    <<  ì—”ë“œ í¬ì¸íŠ¸  >> =========================

# openai ë‹¨ì¼ ëª¨ë¸ ì—”ë“œí¬ì¸íŠ¸
# @router.post("/chatbot")
# async def chatbot_endpoint(request: QuestionRequest):
#     response = pipeline.get_openai_response(request.question)
#     return {"answer": response}

# ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ í†µí•© ì—”ë“œí¬ì¸íŠ¸
@router.post("/chatbot")
async def chatbot_endpoint(request: QuestionRequest):
    """ëª¨ë“  ìœ í˜•ì˜ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” í†µí•© ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # ì§ˆë¬¸ ìœ í˜• ê°ì§€ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜)
        question = request.question.lower()

        # ë¹„ì¦ˆë‹ˆìŠ¤ ì¡°ì–¸ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
        business_keywords = ["ì¶”ì²œ", "ì¡°ì–¸", "ì „ëµ", "ì§‘ì¤‘", "ëŠ˜ë¦¬ê¸°", "í–¥ìƒ", "ê°œì„ ", "ë¶„ì„"]
        is_business_question = any(keyword in question for keyword in business_keywords)

        # ëª¨ë¸ ë¹„êµ ìš”ì²­ í™•ì¸
        compare_keywords = ["ë¹„êµ", "ë‘ ëª¨ë¸", "ë‹¤ë¥¸ ëª¨ë¸"]
        is_compare_request = any(keyword in question for keyword in compare_keywords)

        if is_compare_request:
            # ëª¨ë¸ ë¹„êµ ìš”ì²­ì¸ ê²½ìš°
            return pipeline.compare_models(request.question)
        elif is_business_question:
            # ë¹„ì¦ˆë‹ˆìŠ¤ ì¡°ì–¸ ì§ˆë¬¸ì¸ ê²½ìš°
            advisor_pipeline = pipeline.create_business_advisor_pipeline()
            response = advisor_pipeline.invoke(request.question)
            return {"answer": response}
        else:
            # ì¼ë°˜ ì§ˆë¬¸ì¸ ê²½ìš°
            response = pipeline.get_openai_response(request.question)
            return {"answer": response}

    except Exception as e:
        print(f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {"error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

# openai, claude ëª¨ë¸ ë¹„êµ ì—”ë“œí¬ì¸íŠ¸
@router.post("/compare")
async def compare_models(request: QuestionRequest):
    return {"comparison": pipeline.compare_models(request.question)}

# ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ì—”ë“œí¬ì¸íŠ¸
@router.post("/business-advisor")
async def business_advisor_endpoint(request: QuestionRequest):

    # ğŸ• ë§Œë“¤ë©´ ì‚­ì œí•  ì½”ë“œ
    business_advice = pipeline.get_business_advice(request.question)
    return {"answer": business_advice}

    # ğŸ• ë§Œë“¤ë©´ ì‚´ë¦´ ì½”ë“œ
    # # ë¹„ì¦ˆë‹ˆìŠ¤ ì–´ë“œë°”ì´ì € íŒŒì´í”„ë¼ì¸ ê°€ì ¸ì˜¤ê¸°
    # advisor_pipeline = pipeline.create_business_advisor_pipeline()
    #
    # # ì§ˆë¬¸ì— ëŒ€í•œ ë¶„ì„ ë° ì¡°ì–¸ ìƒì„±
    # response = advisor_pipeline.invoke(request.question)
    # return {"answer": response}